{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Steps\n",
    "#### • Make a Data Frame with required columns DONE\n",
    "#### • Make function that is called for each file DONE\n",
    "#### • Extract The remaining two sections DONE\n",
    "#### • Calculate the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbs\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import *\n",
    "import urllib\n",
    "import html2text\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "stop_words_file = open('StopWords_Generic.txt','r')\n",
    "for word in stop_words_file:\n",
    "    stop_words.append(word.lower().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dictionary = pd.read_csv('master_dictionary.csv',usecols=['Word','Negative','Positive'])\n",
    "master_dictionary['Word'] = master_dictionary['Word'].str.lower()\n",
    "positive_words = master_dictionary[master_dictionary['Positive']!=0]['Word'].values\n",
    "negative_words = master_dictionary[master_dictionary['Negative']!=0]['Word'].values\n",
    "\n",
    "\n",
    "constraining_words = pd.read_excel('constraining_dictionary.xlsx')['Word'].str.lower().values\n",
    "uncertain_words = pd.read_excel('uncertainty_dictionary.xlsx')['Word'].str.lower().values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_prepend = 'https://www.sec.gov/Archives/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cik_list = pd.read_excel('cik_list.xlsx')\n",
    "columns = ['mda_positive_score',\n",
    " 'mda_negative_score',\n",
    " 'mda_polarity_score',\n",
    " 'mda_average_sentence_length',\n",
    " 'mda_percentage_of_complex_words',\n",
    " 'mda_fog_index',\n",
    " 'mda_complex_word_count',\n",
    " 'mda_word_count',\n",
    " 'mda_uncertainty_score',\n",
    " 'mda_constraining_score',\n",
    " 'mda_positive_word_proportion',\n",
    " 'mda_negative_word_proportion',\n",
    " 'mda_uncertainty_word_proportion',\n",
    " 'mda_constraining_word_proportion',\n",
    " 'qqdmr_positive_score',\n",
    " 'qqdmr_negative_score',\n",
    " 'qqdmr_polarity_score',\n",
    " 'qqdmr_average_sentence_length',\n",
    " 'qqdmr_percentage_of_complex_words',\n",
    " 'qqdmr_fog_index',\n",
    " 'qqdmr_complex_word_count',\n",
    " 'qqdmr_word_count',\n",
    " 'qqdmr_uncertainty_score',\n",
    " 'qqdmr_constraining_score',\n",
    " 'qqdmr_positive_word_proportion',\n",
    " 'qqdmr_negative_word_proportion',\n",
    " 'qqdmr_uncertainty_word_proportion',\n",
    " 'qqdmr_constraining_word_proportion',\n",
    " 'rf_positive_score',\n",
    " 'rf_negative_score',\n",
    " 'rf_polarity_score',\n",
    " 'rf_average_sentence_length',\n",
    " 'rf_percentage_of_complex_words',\n",
    " 'rf_fog_index',\n",
    " 'rf_complex_word_count',\n",
    " 'rf_word_count',\n",
    " 'rf_uncertainty_score',\n",
    " 'rf_constraining_score',\n",
    " 'rf_positive_word_proportion',\n",
    " 'rf_negative_word_proportion',\n",
    " 'rf_uncertainty_word_proportion',\n",
    " 'rf_constraining_word_proportion',\n",
    " 'constraining_words_whole_report']\n",
    "variables = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "WNlemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We dont Lemmatize words because the lists already include inflections of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complex_word(word):\n",
    "    count = 0\n",
    "    for letter in word:\n",
    "        if letter in ['a','e','i','o','u']:\n",
    "            count +=1\n",
    "    if(word[-2:] in ['es','ed']):\n",
    "        count -=1\n",
    "        \n",
    "    return count > 2\n",
    "\n",
    "\n",
    "def read_sections(file,url):\n",
    "    \n",
    "    MDA_section = re.findall('\\n\\W*item[^a-z0-9]+\\d[a-z]?\\.?[^A-Za-z0-9]*management\\Ws[^A-Za-z0-9]*discussion[^A-Za-z0-9]*and[^A-Za-z0-9]*analysis(.*?)\\n\\W*item[^a-z]+\\d[a-z]?',file,flags=re.DOTALL)\n",
    "    MDA_section.append('')\n",
    "    MDA_section = max(MDA_section,key=len)\n",
    "   \n",
    "    QQDMR_section = re.findall('\\n\\W*item[^a-z]+\\d[a-z]?\\.?[^a-z0-9]*quantitative[^A-Za-z0-9]*and[^A-Za-z0-9]*qualitative[^A-Za-z0-9]*disclosure[s]?[^A-Za-z0-9]*about[^A-Za-z0-9]*market[^A-Za-z0-9]*risk(.*?)\\n\\W*item[^a-z]+\\d[a-z]?',file,flags=re.DOTALL)\n",
    "    QQDMR_section.append('')\n",
    "    QQDMR_section = max(QQDMR_section,key=len)\n",
    "    RF_section = re.findall('\\n\\W*item[^a-z]+\\d[a-z]?\\.?[^a-z0-9]*risk[^a-z0-9]*factors(.*?)\\n\\W*item[^a-z]+\\d[a-z]?',file,flags=re.DOTALL)\n",
    "    RF_section.append('')\n",
    "    RF_section = max(RF_section,key=len)\n",
    "    \n",
    "    return (MDA_section,QQDMR_section,RF_section)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_variables(section):\n",
    "    sent_num = 0\n",
    "    sents = sent_tokenize(section)\n",
    "    \n",
    "    words = [] \n",
    "    for sent in sents:\n",
    "        Words = word_tokenize(sent)\n",
    "        if(len(words)>2):\n",
    "            sent_num +=1\n",
    "        words+= [word for word in Words if word.isalpha() and word not in stop_words and len(word) > 1 and word in master_dictionary['Word'].values]\n",
    "\n",
    "    if(sent_num==0):\n",
    "        words=[]\n",
    "    if len(words)!=0:  \n",
    "          \n",
    "        positive_score = len([word for word in words if word in positive_words])\n",
    "        negative_score = len([word for word in words if word in negative_words])\n",
    "        uncertainty_score = len([word for word in words if word in uncertain_words])\n",
    "        constraining_score = len([word for word in words if word in constraining_words])\n",
    "        positive_score = len([word for word in words if word in positive_words])\n",
    "        word_count = len(words)\n",
    "        polarity_score = (positive_score-negative_score)/(positive_score+negative_score+0.000001)\n",
    "        subjectivity_score = (positive_score+negative_score)/(word_count+0.000001)\n",
    "        average_sentence_length = word_count/sent_num\n",
    "        complex_word_count = len([x for x in words if complex_word(x)])\n",
    "        per_complex_words = complex_word_count/word_count\n",
    "        pos_word_proportion = positive_score/word_count\n",
    "        neg_word_proportion = negative_score/word_count\n",
    "        uncer_word_proportion = uncertainty_score/word_count\n",
    "        const_word_proportion = constraining_score/word_count\n",
    "        fog_index = 0.4 * (average_sentence_length+per_complex_words)\n",
    "        return[positive_score,negative_score,polarity_score,average_sentence_length,per_complex_words,fog_index,complex_word_count,word_count,uncertainty_score,constraining_score,pos_word_proportion,neg_word_proportion,uncer_word_proportion,const_word_proportion]\n",
    "    else:\n",
    "        return [0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "ana_section = []\n",
    "output_variables = []\n",
    "for row_index, row in cik_list.iterrows():\n",
    "    url = (url_prepend + row['SECFNAME'])\n",
    "    response = urllib.request.urlopen(url)\n",
    "    file =response.read().decode('utf-8').lower()\n",
    "    if re.search('<html>',file):\n",
    "        html2text.escape_all = True\n",
    "        file = BeautifulSoup(file,'html5lib').text\n",
    "    mda_section,qqdmr_section,rf_section =  read_sections(file,url)\n",
    "    mda_variables = calc_variables(mda_section)\n",
    "    qqdmr_variables = calc_variables(qqdmr_section)\n",
    "    rf_variables = calc_variables(rf_section)\n",
    "    const_whole_report = len([word for word in word_tokenize(file) if word in constraining_words])\n",
    "    output_variables.append((mda_variables+qqdmr_variables+rf_variables+[const_whole_report]))\n",
    "    print(row_index)\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = cik_list.copy()\n",
    "output_df = pd.concat([output_df,pd.DataFrame(output_variables,columns=columns)],axis=1,ignore_index=True,sort=False)\n",
    "output_df.columns = list(cik_list.columns) + columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('output_variables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
